{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f942d288-be01-42cd-9b84-83529c6769be",
   "metadata": {},
   "source": [
    "## Reduction operation: the sum of the numbers in the range [0, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496946fa-2a28-4c1d-8a6a-2ee0b8fd8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using a function: 4.84 ms ± 70.5 µs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
      "And the result of the sum of numbers in the range [0, value) is: 24989.62328176169\n",
      "\n",
      "Time taken by reduction operation using numpy.sum(): 13.3 µs ± 23.4 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Now, the result using numpy.sum(): 24989.62328176184 \n",
      " \n",
      "Time taken by reduction operation using numpy.ndarray.sum(): 11.5 µs ± 3.85 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Now, the result using numpy.ndarray.sum(): 24989.62328176184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reduc_operation(A):\n",
    "    \"\"\"Compute the sum of the elements of Array A in the range [0, value).\"\"\"\n",
    "    s = 0\n",
    "    for i in range(A.size):\n",
    "        s += A[i]\n",
    "    return s\n",
    "\n",
    "# Secuencial\n",
    "\n",
    "value = 5*10**4\n",
    "\n",
    "X = np.random.rand(value)\n",
    "\n",
    "# Para imprimir los pimeros valores del array\n",
    "\n",
    "# print(X[0:12])\n",
    "\n",
    "# Utilizando las operaciones mágicas de ipython\n",
    "\n",
    "tiempo = %timeit -r 2 -o -q reduc_operation(X)\n",
    "\n",
    "print(\"Time taken by reduction operation using a function:\", tiempo)\n",
    "\n",
    "\n",
    "print(f\"And the result of the sum of numbers in the range [0, value) is: {reduc_operation(X)}\\n\")\n",
    "\n",
    "\n",
    "# Utilizando numpy.sum()\n",
    "\n",
    "tiempo = %timeit -r 2 -o -q np.sum(X)\n",
    "\n",
    "print(\"Time taken by reduction operation using numpy.sum():\", tiempo)\n",
    "\n",
    "print(\"Now, the result using numpy.sum():\", np.sum(X),\"\\n \")\n",
    "\n",
    "\n",
    "# Utilizando numpy.ndarray.sum()\n",
    "\n",
    "tiempo= %timeit -r 2 -o -q X.sum()\n",
    "\n",
    "print(\"Time taken by reduction operation using numpy.ndarray.sum():\", tiempo)\n",
    "\n",
    "print(\"Now, the result using numpy.ndarray.sum():\", X.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41111c-928b-417b-b30d-6e4a27a804a8",
   "metadata": {},
   "source": [
    "a) Librería cupy: En la siguiente celda de código del notebook9 vamos a utilizar el paquete cupy para acelerar dicha operación de reducción. Como se ha explicado, la libreria cupy es una librería muy similar a la librería numpy específicamente diseñada para GPUs. De hecho, la mayoría de funciones que hay en numpy tienen el mismo nombre en cupy. Por tanto, de las 2 formas de hacer la suma de los elementos del array, por medio de la función reduc_operation y por medio de la función sum de la librería numpy, vamos a usar únicamente la función sum de la librería cupy.\n",
    "\n",
    "Lo que tienes que hacer es modificar el notebook para crear el array en la GPU (usando las funciones de la librería cupy análogas a las de la librería numpy) y utilizar la función sum para calcular la suma de los elementos del array. Como la GPU ya es paralela, no tienes que paralelizar nada más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9d4ad0-356c-45cf-bdbb-3c9ddad5784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using cupy.sum(): 17.4 µs ± 25.4 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Result of the sum using cupy.sum(): 24950.91716312461 \n",
      "\n",
      "Time taken by reduction operation using cupy.ndarray.sum(): 16.4 µs ± 31.2 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Result of the sum using cupy.ndarray.sum(): 24950.91716312461\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp  # Importamos CuPy\n",
    "\n",
    "def reduc_operation(A):\n",
    "    \"\"\"Compute the sum of the elements of Array A in the range [0, value).\"\"\"\n",
    "    s = 0\n",
    "    for i in range(A.size):\n",
    "        s += A[i]\n",
    "    return s\n",
    "\n",
    "# Configuración inicial\n",
    "value = 5 * 10**4  # Tamaño del array\n",
    "\n",
    "# Crear el array directamente en la GPU utilizando cupy.random.rand\n",
    "X_gpu = cp.random.rand(value)  \n",
    "\n",
    "# Para imprimir los primeros valores del array (traspasándolos a la CPU con .get())\n",
    "# print(cp.asnumpy(X_gpu[:12]))\n",
    "\n",
    "# Reducir operación en la GPU con cupy.sum()\n",
    "tiempo = %timeit -r 2 -o -q cp.sum(X_gpu)\n",
    "\n",
    "print(\"Time taken by reduction operation using cupy.sum():\", tiempo)\n",
    "print(\"Result of the sum using cupy.sum():\", cp.sum(X_gpu), \"\\n\")\n",
    "\n",
    "# Alternativamente, usar el método .sum() del array creado por CuPy \n",
    "tiempo = %timeit -r 2 -o -q X_gpu.sum()\n",
    "\n",
    "print(\"Time taken by reduction operation using cupy.ndarray.sum():\", tiempo)\n",
    "print(\"Result of the sum using cupy.ndarray.sum():\", X_gpu.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c81bb4-8a94-40f4-9d2b-117f40c2f9f6",
   "metadata": {},
   "source": [
    "b) Librería Numba: En la siguiente celda de código del notebook10 vamos a utilizar el paquete Numba para acelerar dicha operación de reducción. Como se ha explicado, la libreria Numba te permite crear ufuncs muy similares a las de la librería numpy que se pueden ejecutar en la GPU.\n",
    "\n",
    "Lo que tienes que hacer es crear una ufunc que te permita hacer la reducción del array de forma análoga a las de la librería numpy, y utilizar la función sum para calcular la suma de los elementos del array. Como la GPU ya es paralela, no tienes que paralelizar nada más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c492cc9-d9c8-4569-aca1-1c04ea72df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using Numba kernel (GPU): 409 µs ± 411 ns per loop (mean ± std. dev. of 2 runs, 1,000 loops each)\n",
      "Result of the sum using Numba kernel (GPU): 25018.2432011578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, float64\n",
    "\n",
    "# Kernel de reducción en la GPU\n",
    "@cuda.jit\n",
    "def reduce_kernel(array, result):\n",
    "    # Crear memoria compartida por bloque\n",
    "    shared = cuda.shared.array(shape=256, dtype=float64)\n",
    "\n",
    "    # Índice global y local\n",
    "    tid = cuda.threadIdx.x\n",
    "    gid = cuda.blockIdx.x * cuda.blockDim.x + tid\n",
    "\n",
    "    # Copiar datos a memoria compartida (si están dentro del rango)\n",
    "    if gid < array.size:\n",
    "        shared[tid] = array[gid]\n",
    "    else:\n",
    "        shared[tid] = 0.0  # Si está fuera del rango, asignar 0\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Reducción dentro del bloque\n",
    "    step = cuda.blockDim.x // 2\n",
    "    while step > 0:\n",
    "        if tid < step:\n",
    "            shared[tid] += shared[tid + step]\n",
    "        step //= 2\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # El primer hilo escribe el resultado del bloque\n",
    "    if tid == 0:\n",
    "        result[cuda.blockIdx.x] = shared[0]\n",
    "\n",
    "# Función de reducción completa usando GPU\n",
    "def reduce_array_gpu(array):\n",
    "    # Tamaño de bloques e inicialización\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (array.size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    # Arrays en la GPU\n",
    "    d_array = cuda.to_device(array)\n",
    "    d_result = cuda.device_array(blocks_per_grid, dtype=np.float64)\n",
    "\n",
    "    # Primera reducción\n",
    "    reduce_kernel[blocks_per_grid, threads_per_block](d_array, d_result)\n",
    "\n",
    "    # Reducir el resultado en la CPU (cuando los bloques son pocos)\n",
    "    h_result = d_result.copy_to_host()\n",
    "    return np.sum(h_result)\n",
    "\n",
    "# Configuración inicial\n",
    "value = 5 * 10**4  # Tamaño del array\n",
    "\n",
    "# Crear el array con NumPy\n",
    "X = np.random.rand(value)\n",
    "\n",
    "# Medir el tiempo de la reducción en la GPU\n",
    "tiempo = %timeit -r 2 -o -q reduce_array_gpu(X)\n",
    "\n",
    "print(\"Time taken by reduction operation using Numba kernel (GPU):\", tiempo)\n",
    "print(\"Result of the sum using Numba kernel (GPU):\", reduce_array_gpu(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8274cc3-378d-499d-8c05-4cf5530f550b",
   "metadata": {},
   "source": [
    "c) Una vez hayas comprobado que funcionan los anteriores ejercicios, haz una modificación en el notebook que permita darle el valor del número de elementos por la línea de comandos al lanzar a ejecutar el notebook con el gestor de colas sbatch. Una vez hecho esto, crea el shell script que va a usar el comando sbatch para lanzar con SLURM a la cola bohr-gpu para medir el tiempo de ejecución en dicha cola. Llama a dicho fichero submit_reduc_oper-GPU_machine-name-login.sh11 Lánzalo con el valor de 5 ∗ 106, 5 ∗107 y 5∗108 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a06d95c-7f5e-4aee-8f90-db8ffe374635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using cupy.sum(): 17.81 µs ± 0.07 µs per loop\n",
      "Result of the sum using cupy.sum(): 1.7805099431425333e-05\n",
      "\n",
      "Time taken by reduction operation using cupy.ndarray.sum(): 16.76 µs ± 0.02 µs per loop\n",
      "Result of the sum using cupy.ndarray.sum(): 1.676220890134573e-05\n",
      "\n",
      "Time taken by reduction operation using Numba kernel (GPU): 227.08 µs ± 0.01 µs per loop\n",
      "Result of the sum using Numba kernel (GPU): 0.000227081635966897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numba import cuda, float64\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Filtramos los argumentos pasados por Jupyter o IPython\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]  # Esto eliminará los argumentos adicionales\n",
    "\n",
    "# Configuración inicial: agregar argparse para tomar el número de elementos desde la línea de comandos\n",
    "parser = argparse.ArgumentParser(description=\"Reduction Operation GPU\")\n",
    "parser.add_argument('--value', type=int, default=5 * 10**4, help=\"Number of elements in the array\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Obtener el valor de los elementos\n",
    "value = args.value  # Número de elementos a usar\n",
    "\n",
    "# **Uso de CuPy para la reducción en la GPU**\n",
    "X_gpu = cp.random.rand(value)\n",
    "\n",
    "# Reducir operación en la GPU con cupy.sum()\n",
    "tiempo = %timeit -r 2 -o -q cp.sum(X_gpu)\n",
    "print(f\"Time taken by reduction operation using cupy.sum(): {tiempo.best * 1e6:.2f} µs ± {tiempo.stdev * 1e6:.2f} µs per loop\")\n",
    "print(f\"Result of the sum using cupy.sum(): {tiempo.best}\\n\")\n",
    "\n",
    "# **Alternativa con cupy.ndarray.sum()**\n",
    "tiempo = %timeit -r 2 -o -q X_gpu.sum()\n",
    "print(f\"Time taken by reduction operation using cupy.ndarray.sum(): {tiempo.best * 1e6:.2f} µs ± {tiempo.stdev * 1e6:.2f} µs per loop\")\n",
    "print(f\"Result of the sum using cupy.ndarray.sum(): {tiempo.best}\\n\")\n",
    "\n",
    "# **Kernel de reducción en la GPU para Numba**\n",
    "@cuda.jit\n",
    "def reduce_kernel(array, result):\n",
    "    shared = cuda.shared.array(shape=256, dtype=float64)\n",
    "    tid = cuda.threadIdx.x\n",
    "    gid = cuda.blockIdx.x * cuda.blockDim.x + tid\n",
    "    if gid < array.size:\n",
    "        shared[tid] = array[gid]\n",
    "    else:\n",
    "        shared[tid] = 0.0\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    step = cuda.blockDim.x // 2\n",
    "    while step > 0:\n",
    "        if tid < step:\n",
    "            shared[tid] += shared[tid + step]\n",
    "        step //= 2\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    if tid == 0:\n",
    "        result[cuda.blockIdx.x] = shared[0]\n",
    "\n",
    "def reduce_array_gpu(array):\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (array.size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    d_array = cuda.to_device(array)\n",
    "    d_result = cuda.device_array(blocks_per_grid, dtype=np.float64)\n",
    "\n",
    "    reduce_kernel[blocks_per_grid, threads_per_block](d_array, d_result)\n",
    "    h_result = d_result.copy_to_host()\n",
    "    return np.sum(h_result)\n",
    "\n",
    "# Medir el tiempo de la reducción en la GPU usando Numba\n",
    "tiempo = %timeit -r 2 -o -q reduce_array_gpu(X_gpu)\n",
    "print(f\"Time taken by reduction operation using Numba kernel (GPU): {tiempo.best * 1e6:.2f} µs ± {tiempo.stdev * 1e6:.2f} µs per loop\")\n",
    "print(f\"Result of the sum using Numba kernel (GPU): {tiempo.best}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de579f",
   "metadata": {},
   "source": [
    "d) Crea una nueva celda de texto debajo de la última celda de código para explicar los resultados obtenidos por los paquetes cupy y Numba usando la GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895dedd",
   "metadata": {},
   "source": [
    "En este ejercicio, se compararon dos librerías para optimizar una operación de reducción en la GPU: CuPy y Numba. CuPy demostró ser la opción más rápida, con tiempos de ejecución de 17.81 µs y 16.76 µs para las funciones cupy.sum() y cupy.ndarray.sum(), respectivamente. Esto refleja la eficiencia de CuPy, que está diseñada específicamente para trabajar con operaciones de arrays en la GPU, ofreciendo tiempos de ejecución bajos y estables.\n",
    "\n",
    "Por otro lado, Numba, aunque también eficiente, mostró tiempos de ejecución más altos, con 227.08 µs por iteración al utilizar un kernel personalizado para la reducción. Esta diferencia se debe a que Numba ofrece mayor flexibilidad para crear operaciones personalizadas en la GPU, pero la sobrecarga de la compilación y la gestión del kernel hace que no sea tan rápido como las funciones optimizadas de CuPy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
