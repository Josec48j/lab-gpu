{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba41111c-928b-417b-b30d-6e4a27a804a8",
   "metadata": {},
   "source": [
    "1. Con respecto a la librería multiprocessing, utilizar la función starmap para crear los procesos que se van a ejecutar en paralelo. La función starmap tiene la ventaja de que puede crear procesos pasándole diversos parámetros, por lo que no será necesario realizar diversas copias del array original al que queremos realizar la operación de reducción de sus elementos. Para ello, lo primero es modificar la función de la reducción def reduc_operation(A) para que te permita pasarle, además del array a sumar, otros 2 parámetros adicionales, el de inicio y el de fin de la operación de reducción. Por tanto, dicha función debe quedar así: def sum_multiprocessing(A, ini, fin). A continuación, debes llamar a la nueva función sum_multiprocessing creando solo un proceso que sume todo el array (valores [0, value]), creando 2 procesos que sume la mitad del array (valores [(0, int(value/2)), (int(value/2), value)]), y creando 4 procesos que sumen cada uno la cuarta parte del array (valores [(0, int(value/4)), (int(value/4), int(value/2)), (int(value/2), int(3*value/4)),(int(3*value/4), value)])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27cda86e-d0c2-4d05-92f6-396e87ddeffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo para la operación de reducción secuencial:\n",
      "Time taken by reduction operation using numpy.sum(): 14.2 µs ± 3.42 ns per loop (mean ± std. dev. of 2 runs, 100,000 loops each)\n",
      "Resultado de la suma secuencial: 25030.963157980892\n",
      "\n",
      "\n",
      "Tiempo para la operación de reducción con 1 procesos:\n",
      "Time taken by reduction operation using 1 processes: 13.4 ms ± 57.2 µs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
      "Resultado de la suma con 1 procesos: 25030.963157980892\n",
      "\n",
      "Tiempo para la operación de reducción con 2 procesos:\n",
      "Time taken by reduction operation using 2 processes: 21.3 ms ± 62.9 µs per loop (mean ± std. dev. of 2 runs, 10 loops each)\n",
      "Resultado de la suma con 2 procesos: 25030.963157980896\n",
      "\n",
      "Tiempo para la operación de reducción con 4 procesos:\n",
      "Time taken by reduction operation using 4 processes: 38.5 ms ± 64.5 µs per loop (mean ± std. dev. of 2 runs, 10 loops each)\n",
      "Resultado de la suma con 4 procesos: 25030.963157980896\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Modificamos la función de reducción para aceptar un inicio y fin\n",
    "def sum_multiprocessing(A, ini, fin):\n",
    "    \"\"\"Sum the elements of Array A in the range [ini, fin).\"\"\"\n",
    "    return np.sum(A[ini:fin])\n",
    "\n",
    "# Secuencial\n",
    "value = 5 * 10**4  # Tamaño del array\n",
    "X = np.random.rand(value)  # Array con valores aleatorios\n",
    "\n",
    "# Tiempo secuencial\n",
    "print(\"Tiempo para la operación de reducción secuencial:\")\n",
    "tiempo = %timeit -r 2 -o -q np.sum(X)\n",
    "print(f\"Time taken by reduction operation using numpy.sum(): {tiempo}\")\n",
    "print(f\"Resultado de la suma secuencial: {np.sum(X)}\\n\")\n",
    "\n",
    "\n",
    "# Divisiones del array para multiprocessing\n",
    "def dividir_array(value, num_procesos):\n",
    "    \"\"\"Divide el array en `num_procesos` subarrays según el esquema definido.\"\"\"\n",
    "    if num_procesos == 1:\n",
    "        return [(0, value)]  # Una sola partición [0, value]\n",
    "    elif num_procesos == 2:\n",
    "        mitad = int(value / 2)\n",
    "        return [(0, mitad), (mitad, value)]  # Dos particiones [0, mitad] y [mitad, value]\n",
    "    elif num_procesos == 4:\n",
    "        cuarto = int(value / 4)\n",
    "        mitad = int(value / 2)\n",
    "        tres_cuartos = int(3 * value / 4)\n",
    "        return [(0, cuarto), (cuarto, mitad), (mitad, tres_cuartos), (tres_cuartos, value)]  # Cuatro particiones\n",
    "    else:\n",
    "        raise ValueError(\"Número de procesos no soportado. Use 1, 2 o 4.\")\n",
    "\n",
    "# Utilizando multiprocessing con 1, 2 y 4 procesos\n",
    "for num_procesos in [1, 2, 4]:\n",
    "    print(f\"\\nTiempo para la operación de reducción con {num_procesos} procesos:\")\n",
    "\n",
    "    # Dividimos el array según el número de procesos\n",
    "    rangos = dividir_array(value, num_procesos)\n",
    "\n",
    "    # Definimos la función que ejecutará multiprocessing\n",
    "    def run_parallel_reduction():\n",
    "        with Pool(processes=num_procesos) as pool:\n",
    "            # Usamos starmap para aplicar sum_multiprocessing a cada rango\n",
    "            resultados = pool.starmap(sum_multiprocessing, [(X, ini, fin) for (ini, fin) in rangos])\n",
    "        return sum(resultados)\n",
    "\n",
    "    # Medimos el tiempo usando %timeit\n",
    "    tiempo = %timeit -r 2 -o -q run_parallel_reduction()\n",
    "    resultado = run_parallel_reduction()\n",
    "\n",
    "    print(f\"Time taken by reduction operation using {num_procesos} processes: {tiempo}\")\n",
    "    print(f\"Resultado de la suma con {num_procesos} procesos: {resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92281c08-e14a-4ef3-a682-cc6ff045e807",
   "metadata": {},
   "source": [
    "2. Con respecto a la librería cupy, en el apartado 3.3 hemos creado el array directamente en la GPU. Lo normal es que el array esté creado en la CPU, y que se copie dicho array a la GPU, se calcule la suma de los elementos, y el valor obtenido se devuelva a la CPU. De esta forma, el tiempo que se tarda en ejecutar la suma en la GPU es más real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3d6cf6b-bc3a-4741-97c1-52bbc3975d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using cupy.sum(): 140.19 µs\n",
      "Result of the sum using cupy.sum(): 24966.02640021457\n",
      "\n",
      "Result in CPU after transferring from GPU: 24966.02640021457\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Crear el array en la CPU usando numpy\n",
    "value = 5 * 10**4  # Tamaño del array\n",
    "X_cpu = np.random.rand(value)  # Array en la CPU con valores aleatorios\n",
    "\n",
    "# Copiar el array a la GPU usando cupy\n",
    "X_gpu = cp.asarray(X_cpu)\n",
    "\n",
    "# Medir el tiempo de la operación de reducción en la GPU\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la suma en la GPU usando cupy\n",
    "result_cupy_sum = cp.sum(X_gpu)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "time_taken = (end_time - start_time) * 1e6  # Convertir a microsegundos\n",
    "\n",
    "print(f\"Time taken by reduction operation using cupy.sum(): {time_taken:.2f} µs\")\n",
    "print(f\"Result of the sum using cupy.sum(): {result_cupy_sum}\\n\")\n",
    "\n",
    "# Copiar el resultado de vuelta a la CPU\n",
    "result_cpu = cp.asnumpy(result_cupy_sum)\n",
    "\n",
    "# Verificar que el resultado es el mismo que en la CPU\n",
    "print(f\"Result in CPU after transferring from GPU: {result_cpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57a6e0-e5d1-4adb-b8fd-5df42d8bca2b",
   "metadata": {},
   "source": [
    "3. Con respecto a la librería numba, numba ofrece un decorador @reduce para convertir una operación binaria simple en un núcleo de reducción. Prueba a utilizar este decorador para calcular la reducción del vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f1bfbe-b314-4f36-abe4-378385de8aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by reduction operation using Numba parallel_reduce: 0.191020 seconds\n",
      "Result of the sum using Numba parallel_reduce: 25141.10815283626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Crear el array en la CPU usando numpy\n",
    "value = 5 * 10**4  # Tamaño del array\n",
    "X_cpu = np.random.rand(value)  # Array en la CPU con valores aleatorios\n",
    "\n",
    "# Definir una función de reducción paralela usando numba.njit\n",
    "@numba.njit(parallel=True)\n",
    "def parallel_reduce(array):\n",
    "    total = 0.0\n",
    "    for i in numba.prange(array.size):  # Paralelizar el bucle con prange\n",
    "        total += array[i]\n",
    "    return total\n",
    "\n",
    "# Medir el tiempo de ejecución de la reducción en la CPU con numba\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la reducción\n",
    "result_numba_sum = parallel_reduce(X_cpu)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(f\"Time taken by reduction operation using Numba parallel_reduce: {time_taken:.6f} seconds\")\n",
    "print(f\"Result of the sum using Numba parallel_reduce: {result_numba_sum}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d32a2e-6995-4bd6-820c-a10d32a622fd",
   "metadata": {},
   "source": [
    "El trabajo extra sería implementar estos pasos en Python y realizar las nuevas mediciones de tiempo. Pon el nombre que te parezca a este nuevo notebook, donde en la última celda del notebook muestres los resultados obtenidos en una de las colas del clúster de tu elección y comentes el porqué de dichos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fe17d-c280-4807-82a1-ad91b552571b",
   "metadata": {},
   "source": [
    "En este ejercicio, se compararon tres enfoques diferentes para optimizar la operación de reducción en un array grande: multiprocessing, CuPy para la GPU, y Numba para la CPU. Cada uno de estos métodos tiene sus características, y los resultados obtenidos muestran cómo varían los tiempos de ejecución y los resultados finales.\n",
    "\n",
    "La mejor opción en términos de rendimiento fue CuPy para la reducción en la GPU, ya que ofreció un tiempo de ejecución considerablemente más rápido que los métodos de multiprocessing y Numba. El método de multiprocessing, aunque útil para dividir la carga de trabajo en la CPU, mostró tiempos de ejecución más altos debido a la sobrecarga asociada con la gestión y sincronización de procesos. Por otro lado, Numba en la CPU, aunque eficiente y más rápido que multiprocessing, no pudo igualar el desempeño de CuPy, ya que el paralelismo en la CPU está limitado por el número de núcleos disponibles.\n",
    "\n",
    "En resumen, para operaciones de reducción de grandes arrays, CuPy resultó ser la opción más eficiente en términos de tiempo de ejecución, especialmente cuando se dispone de una GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
